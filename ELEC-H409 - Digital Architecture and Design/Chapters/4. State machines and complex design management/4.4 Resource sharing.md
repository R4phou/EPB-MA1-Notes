**Golden rule**: *high-performance components take area and burn power (read they are costly), while low-power ones are designed with low-power in mind and will sacrifice performance to make savings in area & power*.

In general we want to **keep the number of computational resources to bare minimum** to save area and thus the system cost. Which is always the most important parameter no matter if we are in high-performance or low-power computing.

To minimise the number of instantiated components, we can use #resource-sharing.

The idea of #resource-sharing  **is to use the same physical component for computation that could potentially come from 2 different places at 2 different moments in time**.

But to **enable** #resource-sharing we need to implement #control-logic that manages the usage of these resources through HW controlled muxes. This control will occur at run-time.

#project-related:
	For us, the components of each step of AES can be shared because we don't use them at the same time.
	But the LUTs cannot because we need those at the same time.
## Concrete example
We want to make an ALU module with couple of basic arithmetic operations (addition and subtraction). The model here will work in simulation and would result in a synthesisable and implementable logic circuit.![](Pasted%20image%2020231212093400.png)The **synthesis could produce 4 instances of ADD/SUB circuits**. The **problem** is that it is difficult for synthesis tool to figure out that a resource of the adder is used for additions in step 1 and 3 could be potentially the same instance.

This is not efficient unless we provide means to keep the above ALU busy with all 4 arithmetic operations at the same time.
- In some cases we might need 4 operations in parallel, but this is a specific case
- In the model above, parallel execution is not possible since case opcode has only one possible outcome at a time.
To change that, we need to **do some manual 'micro-architectural' tuning**.
### ALU with shared resource
**Focus on control logic** and prepare correct data for the input of a single ADD/SUB circuitry.

We make an operand **preselection** - pure combinatorial circuit, just adds a bit more delay to the data-path, latency remains the same.![](Pasted%20image%2020231212124747.png)
### Difference between the two approaches
Both codes execute the same thing: **2 additions and 2 different implementations**.![](Pasted%20image%2020231212125045.png)**If no sharing**, we have **more resources (2 adders)**, but these could **and should be used concurrently** and will have higher data throughput, so better performance.

If system specification explicitly states that no sharing could occur because the computation is never is never concurrent for example. Then **resource sharing reduces the implementation area (cost) and power**.