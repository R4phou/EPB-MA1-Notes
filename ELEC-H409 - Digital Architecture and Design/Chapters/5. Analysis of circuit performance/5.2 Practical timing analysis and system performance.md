There are two kinds of #TA **Timing Analysis**:
- **Static Timing Analysis** #STA – static means *independent of inputs* and *assuming worst case*; STA is thus pessimistic.
- **Dynamic Timing Analysis** – logic paths are data dependent; by *assuming actual input vectors we can derive the actual logic paths*; **more accurate analysis at expense of more complex computations**
## 5.2.1 Static Timing Analysis
#STA needs the following inputs
- **Design netlist** – it defines logical content & connectivity plus placed & routed design data base which defines geometry aspect of the circuit.
- **Timing constraints** – target clock(s) period, input / output delays, explicit delays of certain paths, clock assumptions etc. supplied in text files with more or less standardized format .
- **Technology information** – gate and & wire delays for ASICs, LUTs and wires in FPGAs; information provided by technology manufacturer (CMOS foundry or FPGA vendor)

During place & routing timing, *constraints are used to drive the implementation process*. This is what we **wish should happen at circuit level**.

During #STA *same constraints are used to see how close or far final circuit is from the objective* – difference between what wishes & reality.
## 5.2.2 Slacks
The **Worst Negative Slack** #WNS - difference between actual arrival time in the critical path and the constraint time (aka worst delay).
- If **WNS < 0** constraints are *too optimistic*!
- If **WNS > 0** by little – *timing is met*
- If **WNS >> 0** we *have a margin*, you could actually increase the actual F or re-run everything with more aggressive timing constraints.

The **Total Negative Slack** #TNS - sum of slacks of all failed paths
- *Shows constraints relevance at system level*
- Difference between few paths that fail by lot (you may optimize a given block), or many paths that fail by little (constraints are maybe to aggressive)

To get a realistic idea of timing, you may do the following$$TP_{i+1} = TP_{i}-WNS$$in the next iteration your target period $TP_{i+1}$ is a corrected value of your previous target period $TP_{i}$ with the value of #WNS.
## 5.2.3 Maximum frequency
In FPGA design flows STA is automatically run at each step and max frequency $F_{max}$ is always reported.

Assume that we have a valid data on the input pin of the launch FF, so #set-up-time and #hold-time  with respect to rising $Clk$ edge, we can then compute **minimum clock period** $T_{min}$ for a given circuit.![](Pasted%20image%2020231227154307.png)The **maximum frequency** is $F_{max}=\frac{1}{T_{min}}$
## 5.2.4 Logic complexity (FPGAs)
Complex combinatorial circuits will be decomposed into multiple LUTs: *this decomposition can be VERY sophisticated depending on optimization targets* (see next section).

Optimization will trade-off:
- **Amount of concurrency** – number of functionally independent LUTs that could run in parallel (LUTs 11, 12, 13 below) 
- **Logic depth** – number of LUTs in series (functionally dependent) number of LUTs delays before the output (below 3 LUTs)
#Logic-depth is crucial since it **defines system critical path(s).**
### Logic depth and critical path
Very complex logic functions might result in **logically deep circuits**.![](Pasted%20image%2020231227154556.png)Logically, deep circuits result in huge minimum period, so low operating frequency (bad performance).

The circuit above is not going to be fast since there are so many accumulated LUT delays. To **improve**, we will try to *modify the computational algorithm* or *insert a FF*.![](Pasted%20image%2020231227154930.png)When inserting FFs, we have to do it so that we **evenly break the critical path**.

The minimum period $T_{min}$ will become shorter, so the maximum frequency will go up and the design can run faster.

However, the *output will be available only after a certain number of cycles*, this is #latency. (3 clock cycles in this example).
### Delay vs Latency trade off
For complex circuits **inserting latency on purpose is often mandatory**, because the *critical paths could be very deep*. Think of instruction decoding stage that has to reach all sub-systems in a micro-processor, or complex arithmetic sub-circuits.

We speak of **Flip-Flop insertion**, or #pipelining; this is the link between the physical design and the system architecture; 
	e.g. in a processor the approach translates into sub-circuits to complete fetch, decode, execute, write operations in pipelined fashion.

We have #pipelining :
- **If we have to compute the same thing over many different data**! The approach is not good for a single data unit computation;
- This is because the *total computation time per unit does not change*; you have better $F_{max}$, but more cycles to complete;
- *By supplying one input data at each clock cycle, we will have one output data at each cycle; this results in higher data throughput and reduction in total execution time*.
## 5.2.5 Improving design performance
### At RTL/flow level
- **Design flow tuning** – manipulate different design optimization objectives: *chose between performance, area or power as a prime optimization target*
	- easiest thing to do since just a choice of an EDA SW parameter: you change, run sit & wait for result
	- you *only pay run-time* (could be significant for bigger designs)
- **Constraints tuning** – tightening (or sometimes relaxing) timing objectives for your design
	- They *drive optimization process during place & route*
	- Could be easy or complex *depending on the design and your understanding of it*
- **RTL rewriting for critical path modules** – tracing down critical paths and enabling local RTL modifications; this can be easy... or VERY complex
- **Micro-architecture change** – complete system change and re-design; 
	- VERY complex, done only if really needed
### At device level
- Easiest way to do it: **use more aggressive technology**; 
	- better CMOS devices for ASICs/FPGAs at the expense of power & cost
- CMOS process is subject to **local variations** due to IC manufacturing process;
	- circuits from the same wafer may have differences and will be binned according to their performance;
	- faster devices will sell for more;
	- this difference is more significant with advanced CMOS technologies
- So, FPGAs come with different **speed grades** ranging from lower to higher performance (same FPGA device family, and even ICs made on the same wafer)
- *Faster FPGA device will have better timing of different components* (LUTs, memory devices etc.); you can try this out, but use relatively complex design

If justified you could pick a **faster FPGAs** to improve your design performance, but you will have to **pay more** (that difference may be less than the dev time!).
