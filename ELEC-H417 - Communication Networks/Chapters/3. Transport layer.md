#chap3 
The goal of this chapter is to understand the principles behind the transport layer services: #multiplexing, #demultiplexing, **reliable data transfer**, #flow-control, #congestion-control. 

But also learn about the **Internet transport layer protocols:** #UDP (connection-oriented), #TCP (connection-oriented reliable transport), TCP congestion control.
## 3.1 Transport layer services
Transport services provide **logical communication** between application processes running on different hosts.

Transport protocols actions in end systems are either #sender or #receiver:
- #Sender breaks the application messages into *segments* then passes to the *network layer*.
	- Is passed an application-layer message
	- Determines segment header fields values
	- Creates segment
	- Passes segment to IP
- #Receiver reassembles the segments into messages then passes the message to the *application layer*.
	- Receives segment from IP
	- Check header values
	- Extracts application-layer message
	- Demultiplexes message up to application via socket.

The #network-layer is the logical communication between **hosts**.
The #transport-layer is the logical communication between **processes** that relies on and enhances the network layer services.

*Household analogy* #analogy
12 kids in Ann’s house sending letters to 12 kids in Bill’s house: 
- hosts = houses 
- processes = kids
- app messages = letters in envelopes
- transport protocol = Ann and Bill who demux to in-house siblings
- network-layer protocol = postal service.

In this chapter, we will mostly talk about #TCP and #UDP.
## 3.2 Multiplexing and demultiplexing
Those are #process.
![](Pasted%20image%2020231005103705.png)
#multiplexing at the #sender:
- handle data from multiple sockets
- add transport header (later used for demultiplexing).
$\implies$ it **adds transport headers** that contains the *destination port numbers* of the message.

#demultiplexing at the #receiver:
- Use header info to deliver the received segments to the correct socket.
$\implies$ it is like a *sorting* of the *transport headers to know which packet goes to which socket*
### Demultiplexing
The host receives IP #datagram (from #L3):
- **Each datagram** has a *source IP address* and *a destination IP address*.
- **Each datagram** carries one *transport-layer segment*.
- **Each segment** has a *source* and *a destination port number*.

The #host uses the *IP addresses and port numbers* to direct the segment to the appropriate socket.
![](Pasted%20image%2020231005103951.png)
### Connectionless demultiplexing - UDP
When the receiving host receives #UDP segment, it *checks the destination port number in the segment* and *directs the UDP segment to the socket* with that #port-number.
$\implies$ **IP/UDP datagrams with same destination port number, but different source IP addresses and/or source port numbers will be directed to same socket at receiving host**.![](Pasted%20image%2020231005104109.png)Note that when creating a socket, the #port-number of *host-local* must be specified (in red on the image).
### Connection-oriented demultiplexing - TCP
The #TCP #socket is identified by a **4-tuple** that contains: *source IP address*, *source port number*, *destination IP address* and *destination port number*. 
	Note that the #socket is determined by the #IP-address **and a** #port-number, it allows to establish a connection between two devices over a network by representing an **unique endpoint**.
	While a #port-number is a 16-bit unsigned integer that identify a **specific endpoint**.
	$\implies$ 1 port number can be used for many different sockets! But a socket only has 1 port number.

The **demux**: the *receiver* uses all four values to *direct the segment to the appropriate socket*.

The server may support **many** **simultaneous** TCP sockets, each other socket is identified by its own 4-tuple and *each socket is associated with a different connecting client*.
![](Pasted%20image%2020231008160857.png)
### Summary
Multiplexing, demultiplexing: based on segment, datagram header field values.
#UDP: #demultiplexing using **destination port number (only)**.
#TCP: #demultiplexing using **4-tuple**: source and destination IP addresses, and port numbers

$\to$ **Multiplexing/demultiplexing happen at all layers**!
## 3.3 Connectionless transport: UDP
#UDP (User Datagram Protocol) is a #connectionless protocol, which means that there is **no handshaking between** the UDP **sender and receiver** and that **each UDP segment is handled independently** of the others.

But it also has its **advantages**:
	It **doesn't need a connection** establishment (that could have added a RTT delay).
	It is **simple** because there are no connection state at the sender nor at the receiver
	It has a  **small header size**
	There is **no congestion control** (can blast away as fast as desired and can function in the face of congestion)! 
Therefore, it is used for:
- streaming multimedia apps (loss tolerant, rate sensitive)
- DNS
- SNMP
- HTTP/3
If a reliable transfer is needed over UDP (e.g.: HTTP/3), add a needed reliability at application layer and add a congestion control at the application layer.
![Chapter_3](Chapter_3.pdf#page=27)

Here is an **UDP segment header**.
![](Pasted%20image%2020231005110158.png)The #checksum allows to ensure the integrity of the data, it is a sum of all the 16 bit words (formed with the UDP header and data) with one-complement's addition.
## 3.4 Principles of reliable data transfer
#reliable-data-transfer #RDT
This principle comes from the **abstraction**, an hypothesis that every package that goes through the channel is received without problem.
![](Pasted%20image%2020231005112408.png)
Now, we want to understand what is wrong and fix it! But the **complexity of reliable data transfer protocol depends** strongly on the **characteristics of the unreliable channels**.
![](Pasted%20image%2020231005112631.png)
Let's assume that the **sender and receiver** do not know the *"state"* of each other unless it is communicated via a message.
	This is important because one sender may not know that the receiver is out of order for example. This needs to be taken into account.
### 3.4.1 Interfaces
A #reliable-data-transfer #protocol #RDT interfaces, it goes from the sender to the receiver by passing through the unreliable channel with the use of the **4 functions explained below**.
![](Pasted%20image%2020231008162719.png)
### 3.4.2 Unreliable channel (errors *and* loss)
**Channel assumption**: underlying channel can also lose packets (data, #ACK - acknowledgement).
- #checksum, sequence numbers, ACKs, retransmissions will be of help … but not quite enough

The **approach**: the *sender waits a "reasonable" amount of time for the ACK* then:
- Retransmits if no ACK is received in this time
- If pkt or ACK is delayed (but not lost):
	- Retransmission will be duplicate, but the sequence numbers already handle this, so the receiver must specify the sequence number of the packet being ACKed.
- Use a countdown timer to interrupt after a "reasonable" amount of time.

Here are the **4** possible [scenarios](Chapter_3.pdf#page=39):
![](Pasted%20image%2020231005114500.png)
### 3.4.3 Stop and wait operation
Let's study the performance of the #stop-and-wait operation. 
The first bit is transmitted in t=0, *when the last bit arrives at the receiver*, the #ACK is sent. *When the ACK is received by the sender*, it *sends the next packet* at  $t=RTT + L / R$
$$U_{sender} : \text{utilisation - fraction of time sender busy sending}$$
This is *not optimal because the sender waits a useless amount of time before sending another packet*.
We can see that **only 0.027% of time is used by the sender to send data** !
![](Pasted%20image%2020231005115108.png)
A solution might be to *send bigger packets* (**increase L**), but it is *not a good idea* because it creates more congestion on the internet!
### 3.4.4 Pipelining
#Pipelining: the sender allows **multiple "in-flight"**, yet-to-be-acknowledge packets.
- *Range of sequence numbers must be increased*
- There is thus *buffering* at sender and/or receiver.
![](Pasted%20image%2020231005152947.png)
We need to be careful as there may be difficulties to handle errors, dependencies, resource contention etc.
#### 3.4.4.1 Go-back-N
#Go-back-N at the #sender: 'window' up to N consecutive transmitted but unACKed packets.
![](Pasted%20image%2020231006143827.png)
A **cumulative ACK**: ACK(n), ACKs all packets up to, including sequence numbers n.
- on receiving ACK(n): move window forward to begin at $n+1$.

The timer is set for the oldest in-flight packet.

If the **timeout(n)** is reached, it retransmits the packet n and all the higher sequence number packets in the window.

---
The #receiver does ACK-only. It always send ACK for correctly-received packet so far, with **highest** **in-order** sequence number.
- may generate duplicate ACKs, need only to remember the *rcv_base*
On **receipt of an out-of-order packet**:
- The receiver can **discard** (don't buffer) **or buffer it**, it is an implementation decision.
- It then **re-ACK packet with highest in-order sequence number**.
![](Pasted%20image%2020231006144951.png)
#Example
![](Pasted%20image%2020231006145007.png)
Note on this example that **after that pkt2** is lost, we **discard all the new pkt that arrives** and send the ACK of the last correctly received pkt before the loss. At the timeout, the sender resend all the pkt after the last ACK received.
#### 3.4.4.2 Selective repeat
 **Receiver individually acknowledges all correctly received packets** (compared to Go-back-N, it ACK and place in a buffer if it is correctly received).
 - **buffers packets**, as needed, for eventual in-order delivery to upper layer 
 $\implies$ the buffering of packets allows not to discard them and resend them if an earlier packet is lost for example.
 
Sender **times-out/retransmits individually for unACKed packets**
- Sender maintains timer for each unACKed pkt
#selective-repeat #Example 
![](Pasted%20image%2020231008165200.png)

Sender window
- N consecutive sequence numbers
- limits sequence numbers of sent, unACKed packets
![](Pasted%20image%2020231006152604.png)
![](Pasted%20image%2020231006152618.png)
A problem can occur, because the **receiver can not see the sender side**. Therefore, it can receive a packet with the **same sequence number as a previous one** (see example below).
![](Pasted%20image%2020231008165452.png)Indeed, the window being of 3 and the receiver having received the 3 packets, it moves in the receiving list. And a new item 0 will arrive and be accepted, but it should not as it is the SAME pkt0 as the first sent!

Therefore, the **window size should be smaller than the sequence number size** (I would say less than 75%).$$windowSize < 0.75 seq \#Size$$
## 3.5 Connection-oriented transport : TCP
#Connection-oriented-transport #TCP ![](Pasted%20image%2020231228105842.png)
### 3.5.1 Segment structure
The A bit is the acknowledge bit.
![](Pasted%20image%2020231013141925.png)
Sequence numbers are the byte stream "number" of the first byte in a segment's data

The #sequence-numbers is a byte stream number of the first byte in the segment's data.
The #ACK is the #sequence-numbers of next byte expected from the other side (cumulative ACK).
$\implies$ It is up to the implementer to handle how the receiver handles out-of-order segments.![](Pasted%20image%2020231228110406.png)
### 3.5.2 Reliable data transfer
It will send as ACK the position of the next byte it would like to receive. Here we receive byte 42, but it ACKs byte 43!
![](Pasted%20image%2020231013142958.png)

The #TCP #timeout needs to be **longer than** the #RTT but **not too short** because it would lead to premature timeout and unnecessary retransmission and **not too long** because it would lead to a slow reaction to a segment loss.
#SampleRTT: measured time from segment transmission until ACK receipt and ignore transmissions, will vary, want estimated RTT smoother.
#EstimatedRTT:$= (1-\alpha)* \text{EstimatedRTT}+\alpha*\text{ SampleRTT}$ with a typical value of $\alpha=0.125$
![](Pasted%20image%2020231013144342.png)
There are a few samples that are way above the expectations. It looks like a Gaussian distribution (median line = estimated).
#### Sender (simplified)
When **data is received from the application layer**
- Create a segment with a #sequence-numbers 
- #sequence-numbers is byte stream number of the first data byte in the segment
- Start the time if not already running (the expiration interval is **TimeOutInterval**)

When **timeout**
- Retransmit segment that caused timeout
- Restart the timer

When **ACK received**
- if ACK acknowledges previously unACKed segments
- Update what is known to be ACKed
- Start the timer if there are still unACKed segments.
#### Scenarios
![](Pasted%20image%2020231228111229.png)
**TCP fast retransmit**: if the sender receives 3 additional ACKs for the same data ("triple duplicate ACKs"), it resend an unACKed segment with the smallest sequence number.
	This is because a lost segment is likely, it **doesn't wait for timeout** to be sure, it just retransmits earlier.
### 3.5.3 Flow control
The **receiver controls the sender**, so that the sender won’t overflow receiver’s buffer by transmitting too much, too fast.
![](Pasted%20image%2020231013152234.png)
The TCP #receiver advertises the free buffer space in rwnd field in TCP header.
- RcvBuffer size set via socket options (default is generally 4096 bytes)
- Many OS autoadjust RcvBuffer

The #sender limits the amount of unACKed data to the received *rwnd*. It guarantees that the **receive buffer will not overflow**.
![](Pasted%20image%2020231016174111.png)
### 3.5.4 Connection management
This step concerns the **handshake** between the sender and the receiver before sending data. #handshake
#### 2-ways handshake
Can work if there is no problem, but won't work when the sender wants to resend the data.
![](Pasted%20image%2020231228112309.png)
#### TCP 3-way handshake
Therefore a 3-way handshake is better. **Sender sends a start**, **receiver sends a start**, **sender sends a go**!
![](Pasted%20image%2020231013153321.png)
#### Closing a TCP connection
The client and the server both close their side of the connection. They send the TCP segment with #FIN bit = 1. They respond with an ACK.

Note that simultaneous FIN exchanges can be handled.
## 3.6 Principles of congestion control
#congestion-control 
**Informally**: “too many sources sending too much data too fast for network to handle.
It **manifests** itself by *long delays* due to queuing in router buffers or *packet losses* due to buffer overflow at routers.
[Chapter_3](Chapter_3.pdf#page=85). #skip
## 3.7 TCP Congestion control
Goal, determine the right sending rate.
### 3.7.1 AIMD
#AIMD **Additive Increase Multiplicative Decrease**
The approach is that the **senders can increase the sending rate until the packet loss occurs**, then it *decreases the sending rate*.
![](Pasted%20image%2020231013154413.png)
The sending rate is cut in half on loss detection by the triple duplicate ACK and cut to 1 MSS (maximum segment size) when loss is detected by timeout.
### 3.7.2 CUBIC
#Cubic is better than AIMD to probe for usable bandwidth.

$W_{Max}$ is the sending rate at which the congestion loss was detected.

After a cutting rate/window in half on loss. Initially the ramp to $W_{max}$ goes faster bu then it goes slower (nice curve).
![](Pasted%20image%2020231013154809.png)

#skip