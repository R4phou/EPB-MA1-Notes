In opposition of a #top-down-parser that does #produce and #match based on a #leftmost-derivation. A #bottom-up-parser (BUP) is a #parser that works in a completely reverse way.
## 6.1 BUP
They **build the parse tree from the bottom to the top**, it is often *more efficient* since they deduce the nodes of the parse tree based on the actual input (and not the #look-ahead).

The most prominent class of #bottom-up-parser is based on two actions: #shift and #reduce. It works like this:
1. The #shift action allows to **move the terminals from the input to the top of the stack**.![](Pasted%20image%2020231110092602.png)
2. They **apply the grammar *in reverse***. The parser looks for a so-called **handle** on the top of the stack. (i.e. the right-hand side $α$ of some grammar rule $A → α$). When this #handle is present, the parser can perform a #reduce: it **pops the handle $\alpha$ and push $A$ instead**. This way, the parser unravels a parse tree from the bottom to the top. (here for a *Reduce of the rule $B \to Aa$*)![](Pasted%20image%2020231110093217.png)
3. The aim of the parser is **to end up with only the start symbol $S$ on the stack**. This means that a derivation has been produced for the whole string *in reverse order*. The #bottom-up-parser builds a #rightmost-derivation in #reverse-order. (As opposed to the #top-down-parser that stops when reaching an **empty stack**).

Here is an example:![](Pasted%20image%2020231110094603.png)
The **final configuration** is an #accepting-configuration, it means that the **start symbol of the grammar is on the top of the stack** and **the input is empty**.

Note that the #bottom-up-parser has a choice to make at the second step. He can either Reduce (as on the example above) or Shift again. But if it shifted again, there would have been a problem because it would have been stuck with a $+$ symbol on the stack that can not be removed by any rule of the grammar. Therefore, the **bottom-up parser is non-deterministic!** (here a #shift-reduce conflict).
### 6.1.1 Systematic construction of a BUP
#Skip [info-f-403](info-f-403.pdf#page=161).
### 6.1.2 Non-determinism in BUP
The #BUP can have problems of #non-determinism. There are **two sources of this**: the #reduce-reduce conflict and the #shift-reduce conflict.
 - #reduce-reduce **conflict**: occurs when the **top of the stack is the handle of two different rules** and the **parser cannot decide which rule to reduce**. 
 - #shift-reduce **conflict**: occurs when the **top of the stack constitutes a handle to some rule,** but the **parser cannot determine whether it should continue shifting or whether it should reduce now**.![](Pasted%20image%2020231110100225.png)
### 6.1.3 Viable prefixes
To **help the parser resolve** the #shift-reduce conflicts, we will list all the #viable-prefix of the grammar. But in order to do so, we must observe a relationship between the stack contents  during an accepting run of the bottom-up parser on input w and a rightmost derivation of $w$.

The **proposition** here (demonstrated [here](info-f-403.pdf#page=164)) is that link. 
	Let $G = 〈V , T , P , S〉$ be a #CFG, and let $P'_{G}$ be its corresponding bottom-up parser. 
	Let $〈q_{i} , w , \gamma Z_{0}〉$ be a *configuration reached along an accepting run of* $P'_{G}$ (i.e., a configuration where $P'_{G}$ is neither in one of the intermediate states introduced for the Reduce, nor in $q_{a}$ ). Then: $$
S \implies^{*}\gamma^{R}\cdot w
$$along a rightmost derivation.
- $\gamma$ is what we have put on the stack by means of reduce and shifts
- $w$ is the remaining input
---
#definition 
A #viable-prefix of a CFG $G = 〈V , T , P , S〉$ is a **prefix of a right-sentential form** that can occur (in reverse) on the stack during an accepting run of the associated bottom-up parser $P'_{G}$.

Then,  $p\in (V \cup T)^*$ is a **viable prefix** iff there is a word $w\in L(G)$ and an *accepting run*$$(q_{i},w,Z_{0})=(q_{1},w_{1},\gamma_{1}Z_{0})⊢_{P'_{G}}\dots⊢_{P'_{G}}(q_{j},w_{j},\gamma_{j}Z_{0})⊢_{P'_{G}}\dots⊢_{P'_{G}}(q_{n},w_{n},\gamma_{n}Z_{0}) =(q_{a},\epsilon,\epsilon)$$of $P'_{G}$ s.t. $p = \gamma_{j}^R$ for some $j$ s.t. $q_{j}=q_{i}$.
***
This set of viable-prefixes can be infinite. ($Exp+Exp+\dots+Exp$).

An #example of a set of viable prefixes:![](Pasted%20image%2020231114171509.png)
## 6.2 The canonical finite state machine #CFSM
This section will explain how to build from a #CFG $G$, a #finite-automaton **recognising exactly the** #viable-prefix of $G$. This automaton can be instrumental in **building deterministic** #bottom-up-parser.

---
#definition **CFSM item**
Given a grammar $G = 〈V , T , P , S〉$, an #CFSM #item of $G$ is a **rule of the form** $$A\to\alpha_{1}\cdot\alpha_{2}$$where $A\to\alpha_{1}\alpha_{2}\in P$ is a rule of $G$. 
We denote $Items(G)$ the **set of items of G**.

An #CFSM #item is simply a *grammar rule where we have inserted a '$\cdot$' at some point in the right-hand part* **in order to mark the current progress of the CFSM**.
***
So for the rule $S\to A\$\text{}$, the automaton will pass three states:![](Pasted%20image%2020231114173531.png)For the moment, the automaton is **not sufficient to accept all viable prefixes**. We need to **incorporate the fact that $A$ can be derived as $aCD$ in the initial state**.![](Pasted%20image%2020231114174251.png)This is called the #closure operation: *writing all the possible derivation from the next token to be read* (here $A$). **It needs to be applied to all the states of the CFSM**.

The #items from the **top part of the sates** form the #kernel of the state. We keep it separated to ease the identification of the states since the *closure of a given kernel is always the same*.![](Pasted%20image%2020231114174817.png) #example of #CFSM for the grammar defined at the end of section [6.2](info-f-403.pdf#page=168).

---
#definition 
Let $G = 〈V , T , P , S〉$ be a #CFG. Its #CFSM (canonical finite state machine) is the #DFA:$$CFSM(G)=〈Q,V \cup T , \delta , q_{0},F〉 $$where:
1. The set of states $Q$ is the set of all sets of G’s items: $Q = 2^{Items(G)}$; 
2. the initial state $q_{0} = Closure({S → •α | S → α ∈ P })$ is obtained by taking the closure of all the items obtained from the rules where S is the left-hand side, and where the • appears at the initial position (on the left of the right-hand side);
3. For all $q\in Q$, for all $a\in V\cup T:$$$\delta(q,a)=Closure(CFSMSucc(q,a))$$That is the transition function is obtained by first **computing the successors** of q by a (hence by advancing the • one position to the right in the relevant items), and then taking the closure of the resulting set.
4. All the states are accepting but the empty set, which is considered as an error state: $F=Q\text{ except } \{\phi\}$
##### Theorem
For all #CFG $G$: #CFSM (G) accepts the set of all viables prefixes of G.
***
### Formalism to build a CFSM
To build a #CFSM, we have two steps.

The **first step** is to determine the #closure operation (see [algorithm 9](info-f-403.pdf#page=169)). It is a *fixed point algorithm*, to **adds items of the form $B→•β$ for every item of the form $A→α_{1}•Bα_{2}$ where the • is followed by some variable $B$**. This operation is carried on up to the moment where *no more items can be added to the set*, which is then returned.

The **second step** it to **compute the successors of items**. We use the notion of #successor, for that we define as a function that receives a **set of items** $I ⊆ Items (G)$ and a **terminal** $a ∈ T$, and returns the set $CFSMSucc (I , a)$ of all the items obtained from $I$ after reading $a$.

This is obtained by selecting, from $I$ , all the items of the form $A→α_{1}•aα_{2}$ , where the • is immediately followed by $a$; and by moving the • one position to the right, in order to reflect the progress of the automaton. Formally$$FSMSucc (I , a) = \{A → α_{1}a • α_{2} \mid A → α_{1} • aα_{2} ∈ I\}$$Finally, the **construction of the CFSM** is straightforward.
## 6.3 LR(0) parsers
The #LR0 #parser  **uses no look-ahead**. They are **more powerful** than #LL parsers as there are less restrictions on the grammar. Indeed a LL0 grammar can't contain two rules with the -same left-hand side.

#LR0 parsers are thus capable of parsing grammars that are note entirely trivial without using any look-ahead.
### 6.3.1 LR(0) action table
---
#definition **LR(0) action table**
Let $G = 〈V , T , P , S〉$ be a #CFG with its associated $CFSM(G) = 〈Q, q_{0},V ∪ T , δ, F〉$
Let's assume that:
- $G$'s rules are indexed from $1$ to $n$;
- The non-empty states of $CFSM(G)$ are indexed from $0$ to $m-1$, so that $Q = \{0,1\dots,m-1, \emptyset \}$.

Then the #LR0 #action-table is a table $M$ with $|Q|=m+1$ lines such that for all $0\leq i\leq m, M[i]$ contains a *set of **actions***:
- either an integer $1\leq j\leq n$ denoting a #reduce of **rule number $j$**
- or #shift denoting that the parser must **shift** the next character of the input to the stack
- or #accept denoting that the string read so far is accepted and belongs to the language $L(G)$
- or #error denoting that the string must be rejected. The only state which is associated with this action (for #LR0 grammars) is $\emptyset$.
---
Let's use an example to show what is a #LR0 grammar and how to build the #action-table from it.
	To build this action table, we look for items of the form $A→α•$ in the states of the #CFSM and we associate a #reduce of the corresponding rule to those states.
	When the state contains $A→α_{1}•\alpha_{2}$, we associate a #shift to the state

See [algorithm 10](info-f-403.pdf#page=174) for running it.
![](Pasted%20image%2020231225140259.png)
### 6.3.2 Run of a LR(0) parser
Once the #LR0 #action-table built, let's see how the #parser will run on a given **input string**. To ease the comprehension and clarity, the parser will **not be described as a** #PDA but as an *algorithm that can access a stack* $\mathcal{S}$. The parser is given by [algorithm 11](info-f-403.pdf#page=174). It assumes that the **action table has only one action per cell**. 
The *NextSymbol()* function reads and returns the next symbol on the input (i.e. in the word w).

There is a main *while* loop where the parser **checks** the content of the $LR(0)$ table in the **cell** **given by the top of the stack**, to obtain the action that must be executed, then:
- if this action is an **Error** or an **Accept**, the *execution finishes immediately*;
- if the action is a **Shift**, the *next character is read and stored in variable* $c$; 
- if the action is a **rule number** $i$ (meaning that a **Reduce** of rule number i must be performed), and if rule number $i$ is $A→α$ , then $|α|$ state numbers are popped from the stack, and grammar variable $A$ is stored in $c$.
Finally  the parser computes the next state based on the current state (which is now on the top of the stack) and the symbol $c$ that the #CFSM must read. This new state is pushed to the stack.

For the example above:
	Let's imagine we need to parse the word *aabb$*![](Pasted%20image%2020231225143111.png)
## 6.4 SLR(1) parsers
The problem with #LR0 parsers is that it is not possible to **deterministically parse** every grammar. Like in the example here below. The following grammar is **not LR0**.![](Pasted%20image%2020231225153829.png)But we can still build its #CFSM, it can be seen that there are conflicts in state 1 and in state 12.
	In state 1, the parser cannot decide between performing a *shift* (which needs a $*$ symbol), or *reducing* $Exp\to Prod$.
	Similarly, in state 12, there is a conflict between a shift (of $*$) and a reduce of $Exp\to Exp+Prod$

The way that has been found to lift conflicts:
1. Whenever a state contains an item of the form $A→α•$, perform a #reduce of $A→α$ **if and only if the look-ahead is a symbol from Follow(A)**.
2. Whenever a state contains an item of the form $A→α_{1}•\alpha_{2}$ starts with a terminal, perform a  #shift **if and only if the look-ahead is a symbol from** $First(\alpha_{2})$.

This technique is called #simpleLR1 or #SLR1 ($SLR(1)$) because it uses **one character of** #look-ahead and it can be regarded as a *simplification of a more general LR(1)*.

To formalise it, modify the parsing algorithm of #LR0, but the #CFSM **construction stays the same**. 

The #action-table for #SLR1 $M$ becomes *two-dimensional*. For all states $q$ of the CFSM, and for all symbols $a\in T \cup\{\epsilon\}: M[q,a]$ provides the parser with the actions that it should perform when the current state of the CFSM is $q$ and the next symbol on the input (look-ahead) is $a$.
![](Pasted%20image%2020231225160239.png)Here is an example of run for the word $Id+Id*Id\$$![](Pasted%20image%2020231225160349.png)
## 6.5 LR(k) parsers
While #SRL1 parsers offer a solution to some of the conflicts that exist in #LR0 #parser, there are still some problems as we can see right below.![](Pasted%20image%2020231225161210.png)In this example, both left-hand and right-hand sides can contain references (for example the assignment $**Id=***Id\$$) can be generated. If we try to **use $Follow(R)$ to lift this conflict, it won't work**. 

But we can see that because $Follow(R)$ contains two elements and only one of them causes a conflict. So we need to **refine the notion of $Follow$ to find a way to avoid this conflict**. This will be done by **using information from the** #CFSM.
### 6.5.1 LR(k) CFSM
The #LRk #CFSM extends the notion of #item by adding a potential #context 
***
#definition **LR(k) CFSM item**
Given a grammar $G = 〈V , T , P , S〉$, an #item of $G$ is a rule of the form $A→\alpha_{1}•\alpha_{2}$, $u$, where $A→\alpha_{1}\alpha_{2}\in P$ is a rule of $G$ and $u\in T^{\leq k}$. We denote by $LR(k)-Items(G)$ the **set of** #LRk items of $G$.
***
As said, we extended the notion of item with a *local Follows u* (of size at most $k$). The **intuition behind an item of the form** $A→\alpha_{1}•\alpha_{2}, u$ is that:
- the *parser is trying to reduce* an $A$ from the handle $\alpha_{1}\alpha_{2}$; 
- it *has already reduced* $\alpha_{1}$ *on the top of the stack*; 
- this *occurs in the context* where $A$ is *followed by u*. In other words, if $α_{2} = ε$, the look-ahead should be $u$, otherwise the run of the parser cannot succeed.
#### Compute the LR(k) CFSM
In order to compute an LR(k)-CFSM with such items, we need to **redefine the initial state**, **and the** #closure **operation**.

For the **initial state**, we compute it by taking the closure of the set of items$$\{S\to•\alpha,\epsilon|S\to\alpha\in P\}$$That is, we take the closure of all the items of the form $S → •α$ extended with the local Follow $\epsilon$.

For the #closure **operation**, assume we have an item of the form $A→\alpha_{1}•B\alpha_{2}, u$. 
- We will perform the closure by creating items based on all rules of the form $B\to\beta$. 
- The ***local Follows*** will be computed on the basis of what we expect on the input after $B$. 
	Since we start from the item $A → α_{1} • Bα_{2}$, $u$, we expect on the input the $k$ first characters of $α_{2}$, which we can complete with $u$ if need be. 
That is, we will have all the items of the form $B → •β, u'$, where $u' ∈ First^k(α_{2} · u)$.
[Algorithm 14](info-f-403.pdf#page=183) gives the formalised algorithm for computing this closure operation.

Here is an example![](Pasted%20image%2020231225164547.png)As we can see, the #CFSM takes the notation $\{w_1\dots,w_{n}\}$ for the *local Follows* $u$.
#### Compute the LR(k) action table
#LRk #action-table 
Now that we can compute the LR(k) CFSM, let us see how we can exploit it in a parser. We will adapt the techniques we have introduced for SLR(1). There are mainly two cases to consider: 
1. When a state $s$ contains an item of the form $A→α•aβ, u$ , where $a$ is a terminal (i.e. the dot is directly followed by a terminal), then we must perform a #shift. This will occur in state $s$, and when the look-ahead is some element $y ∈ First^k(aβu)$. Observe that we complete $aβ$ with the local *Follow* that is associated to the item, in order to obtain the #look-ahead.
2. When a state $s$ contains an item of the form $A→α•, u$ , we need to perform a #reduce of the rule $A→α$ . This action will occur in state $s$ and when the #look-ahead is $u$

Here is the master example:![](Pasted%20image%2020231225165504.png)![](Pasted%20image%2020231225165318.png)
### 6.5.2 Running the LR(k) parser
![](Pasted%20image%2020231225165530.png)
ll this algorithm needs is an #action-table indexed by states (for the rows) and #look-ahead(for the columns), and *a way to compute the successor states of the CFSM* (which can be given as a table, as well, and is implicitly represented by the CFSM itself).
### 6.5.3 LR(k) grammars
#LRk are the #bottom-up-parser relative of #LLk #top-down-parser.

---
#definition **LR(k) grammar**
A #CFG $G = 〈V , T , P , S〉$ is #LRk iff for all pairs of rightmost derivations:$$S \implies^*\gamma Ax\implies\gamma\alpha x\implies^{*}w_{1}x
$$$$S \implies^*\delta By\implies\delta\beta y\implies^{*}w_{2}y$$such that $(i) \delta\beta y=\gamma\alpha x'$ and $(ii) First^k(x)=First^k(x')$, we have $\delta B x=\gamma A x'$
***
## 6.6 LALR(k) parsers
We have not seen in details how LALR(k) grammars or parsers works but a little for #LALR1.

#LALR1 is a technique used to compact the #LR1 automaton. The idea is to **merge states that have the same "heart"**.
![](Pasted%20image%2020231225171339.png)
But we need to be careful because it might reintroduce conflicts!
## 6.7 Top-down vs Bottom-up hierarchies
![](Pasted%20image%2020231225135145.png)

---
---



