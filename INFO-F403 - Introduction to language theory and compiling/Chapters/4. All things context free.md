[Syllabus](info-f-403.pdf#page=87).
To introduce this #chap4 let's consider a #CFL, the language of all *palindromes* on {0,1}. Where the two parts of the palindromes are separated by the symbol #.$$L_{pal\#}=\{w\cdot\#\cdot w^R|w\in\{0,1\}\}$$ And the objective is to recognise words that belong to this language, and more generally, **recognize any CFL**.

In order to do so, we need to **add some form of unbounded memory** to the finite automata. We will use a #stack. This new model is called a #pushdown-automata #PDA.

The program for this language can then be rewritten as:
1. **Read the prefix w** up to the occurrence of #, letter by letter, *pushing* each letter on the stack; 
2. Skip the symbol #;
3. **Read the suffix w′**, letter by letter. Compare each letter from the input to the top of the stack. If they differ, or if the stack is empty, reject the word, *otherwise pop the letter*. 
4. If the whole suffix has been read and the stack is empty, accept the word, otherwise reject.

Example for the word: 001#100![](Pasted%20image%2020231019181012.png)
This can be written in a program [you can see here](info-f-403.pdf#page=89).
## 4.1 Context free grammars
![](Pasted%20image%2020231023151912.png)
### 4.1.1 Derivation
A #leftmost-derivation  (resp. #rightmost-derivation )is when there are several variables, we derive the leftmost first (resp. rightmost).![](Pasted%20image%2020231023151857.png)
Here the right is on the top and the left on the bottom.

A #leftmost-derivation : Let $G=〈V , T , P , S〉$ be a #CFG. A **derivation** $w \text{ S } w' \implies w\alpha w'$ of $G$ which is obtained by applying $S\to\alpha$ is *leftmost* iff: $w\in T^*$. It is rightmost iff $w' \in T^*$.

A #derivation-tree is a way to prove that a given word belongs to the language of a grammar. The idea is to generate a tree from the grammar.
![](Pasted%20image%2020231023153137.png)
Given a #CFG $G=〈V , T , P , S〉$, a tree $T$ is a #derivation-tree of the word $w$ iff $T$ is an S-tree and $w$ is obtained by traversing $T$'s leaves from left to right.

Those trees can be **ambiguous** because a word can be derived in multiple ways. We can have two different derivation trees. #ambiguity 
### 4.1.2 Membership problem
Given a #CFG G and a word $w$, does $w \in G$?

Let's assume that the CFG is in the **Chomsky normal form** #CNF meaning that all the rules are of the form:$$A\to BC$$$$A\to a$$$$S\to \epsilon$$
where $A$ is any variable ($A\in V$), $B$ and $C$ are any variable different from the start symbol: $\{B,C\}\subseteq V\backslash\{S\}$ and $a$ is any terminal ($a\in T$).

In order to determine whether a word belongs to a CFG, we use an algorithm detailed in the [syllabus](info-f-403.pdf#page=97). It consists on building tables of the subwords possible.

Once the table built, if there are multiple way's to reach the word. We can conclude that the grammar is capable to generate the word $w$.
## 4.2 Pushdown automata #PDA
### 4.2.1 Definition
A #PDA / #pushdown-automata is a **finite state automaton** augmented with a stack that serves as as memory and at each transition, the automaton can test the value on the top of the stack and modify (push or pop) the top of the stack. #finite

#syntax A **pushdown automata** is a tuple $〈Q, Σ, Γ, δ, q_{0}, Z_{0}, F〉$ such that:
-  $Q$ is a finite set of states
- $\Sigma$ is the (finite) input alphabet
- $\Gamma$ is a finite stack alphabet
- $\delta : Q \times (\Sigma \cup \{\epsilon\}) \times \Gamma\mapsto 2^{Q\times \Gamma^*}$ is the transition function
- $q_{0} \in Q$ is the initial state
- $Z_{0} \in \Gamma$ is the initial symbol on the stack
- $F \subseteq Q$ is the set of accepting states.

The **transitions** in a #PDA are like this:![](Pasted%20image%2020231023161415.png)
- $a$ is the letter that is read on the input
- $\beta$ is the letter on the top of the stack
- $\gamma$ is the replacement of $\beta$ after the transition

There are [examples in the syllabus](info-f-403.pdf#page=101).

A #configuration of a #PDA is triple $$〈q, w, \gamma〉 \in Q ×\Sigma^{*}×\Gamma^{*}$$
-  $q$ is the current state
- $w$ is the remaining input
- $\gamma$ is the stack content

A #configuration-change in a #PDA $P=〈Q, Σ, Γ, δ, q_{0}, Z_{0}, F〉$ is denoted:$$〈q,aw,X\beta〉⊢_{P}〈q',w,\alpha\beta〉 \iff (q',\alpha) = \delta(q,a,X)$$with $a\in \Sigma \cup \{\epsilon\}$ and $X\in \Gamma$.

Here is an example for the palyndrome language.
![](Pasted%20image%2020231023164026.png)

A #PDA **accepts a word** iff there is at last one run reading this word and reaching a final state.

An **accepted language of a PDA** $P=〈Q, Σ, Γ, δ, q_{0}, Z_{0}, F〉$:
1. Its **final state accepted language** denoted $L(P) = \{w \mid \text{there are }q\in F \text{ and } \gamma \in \Gamma^{*} s.t.〈q_{0},w,Z_{0}〉⊢_{P}^{*}〈q,\epsilon,\gamma〉 \}$
2. Its **empty stack accepted language** denoted $N(P) = \{w \mid \text{there is }q\in Q \text{ }s.t.〈q_{0},w,Z_{0}〉⊢_{P}^{*}〈q,\epsilon,\epsilon〉 \}$ 
### 4.2.2 Deterministic pushdown automata #DPDA
A #deterministic #PDA is a PDA where there is no non determinism. That means that there is only one way possible per transition. It is a PDA $P=〈Q, Σ, Γ, δ, q_{0}, Z_{0}, F〉$ such that:
1. For all $q \in Q$, $a \in \Sigma \cup \{\epsilon\}$ and $\gamma \in \Gamma: \delta(q,a,\gamma)$ **has at most one element and**;
2. For all $q\in Q$ and $\gamma \in \Gamma:$ if $\delta(q,\epsilon,\gamma)\neq \phi$, then $\delta(q,a,\gamma)= \phi$ for all $a\in\Sigma$.

The example of the palyndrome without the # is used to help determine what a DPDA is.
### 4.2.3 Equivalence with #CFG 
For all #PDA $P$, $L(P)$ and $N(P)$ **are both context-free languages**. Conversely, for all #CFL $L$, there are PDAs $P$ and $P'$ such that $L(P)=N(P')=L$.
[Proof here](info-f-403.pdf#page=106).
### 4.2.4 Deterministic context-free language
The class of **deterministic context-free languages** is strictly contained in the class of *context-free languages*.$$DCFL ⊊ CFL$$
## 4.3 Operations and closure properties of CFL
If $L_{1}$ and $L_{2}$ are #CFL then:
1. $L_{1} \cup L_{2}$ is a CFL
2. $L_{1}.L_{2}$ is a CFL
3. $L_{1}^{*}$ is a CFL
Proof of 1.: Let $G_{1}$ be a CFG for $L_{1}$ (resp 2). Let $G$ be the grammar with the set of $P_{1}\cup P_{2} \cup \{S\to S_{1} \text{, }S\to S_{2}\}$
$\implies L(G) = L(G_{1}) \cup L(G_{2})$
[Proofs of the others](info-f-403.pdf#page=114).
##### Theorem
The language $L_{abc}=\{a^nb^nc^n\mid n\geq 0\}$ is not a CFL.
The only solution with a PDA is to generate a second stack so that we can remember how much a's there is. But then it is not a PDA anymore but a Turing machine!

The problem with one stack is that we don't know how to remember how much a's there is.

---
If $L_{1}$ and $L_{2}$ are CFL $\to$ $L_{1}\cap L_{2}$ is **not necessarily a CFL**..

$L_{1}=\{a^nb^nc^m\mid n\geq 0,m\geq 0\}$ and $L_{2}=\{a^mb^nc^n\mid n\geq 0,m\geq 0\}$ $\implies L_{1}\cap L_{2}$ is not a CFL.
****

## 4.4 Grammar transformations
In this section, we are going to see how to transform #grammar to ease the implementation of a #parser (see #chap5)
### 4.4.1 Factoring
#Factoring a #grammar consists in modifying the grammar in order not to have two rules with the same left-hand side and a common prefix in the right-hand side.![](Pasted%20image%2020231027161207.png)becomes![](Pasted%20image%2020231027161217.png)
In general:![](Pasted%20image%2020231027161342.png)
### 4.4.2 Removing left-recursion
A #recursion in a #CFG refers **to the occurrence of the left-hand side of a rule in its right-hand side**. It is a #left-recursion if this recursive variable occurs as the first symbol on the right-hand side. 

On the left we talk about **direct** recursion and on the right **indirect** recursion.![](Pasted%20image%2020231027162101.png)
#left-recursion is a big problem for building a #parser. The technique to **remove it**:
1. Transform **indirect** left-recursion into a **direct** left-recursion
2. Transform the **left-recursion** to a **right-recursion**

##### Indirect to direct left-recursion
Every time there is a rule of the form $A\to B\alpha$ and $B\to\beta_{i}$.

We replace $A\to B\alpha$ by: $A\to\beta_{i}\alpha$.

With i going from 1 to n.
##### Direct left-recursion to right-recursion
Let's assume that all **direct left-recursive rules with V at the left hand side** (*left*). And a set of all **other** (non-left-recursive) **rules that have V has the left-hand side** (*right*).![](Pasted%20image%2020231027163849.png) We can **observe that a word which is generated from** $A$ is **necessarily of the form**: $$ww_{1}'w_{2}'\dots w_{k}'$$ where $\beta_{i}$'s and each $w_{i}'$ is generated from one of the $\alpha_{j}$'s.

By using this, we can replace the rules to have $V'$ the recursive variable but we have used the **right-recursion** to generate the sequence of $\alpha_{i}$'s.
![](Pasted%20image%2020231027164252.png)
### 4.4.3 Removing useless symbols
An **useless symbol** is a symbol in the grammar that will never be reached. Here an example of **unproductive symbol**, a symbol that can never disappear (A in this example).![](Pasted%20image%2020231027170406.png)Another possibility is a symbol that is productive (that can produce an output) but can never be reached in any #sentential-form produced from S (here B).![](Pasted%20image%2020231027171020.png)
#### Algorithm to remove unproductive symbols
1. Compute the set *Prod* of productive symbols.
2. Remove the **unproductive** symbols from $G = 〈V , T , P , S〉$ to get $G = 〈V' , T' , P' , S〉$.
	 Where $V' = Prod\cap V\cap\{S\}$ and $P'$ contains all the rules of the form $A \to \alpha\in P$ such that $\alpha\in Prod^*$.
#### Algorithm to remove unreachable symbols
1. Compute the set *Reach* of reachable symbols.
2. Remove the **unreachable** symbols from $G = 〈V , T , P , S〉$ to get $G = 〈V' , T , P' , S〉$.
	 Where $V' = Reach\cap V; T' = Reach \cap T$ and $P'$ contains all the rules of the form $A \to \alpha\in P$ such that $\alpha\in Reach$.
#### Algorithm to remove both
![](Pasted%20image%2020231029104430.png)On the left we have:
- A unproductive
- B productive
- A and B reachable
But if we remove A, the variable B becomes unreachable. **Removing unproductive symbols can create unreachable symbols**. On the contrary, removing unreachable symbols **will not** make variables unproductive.

Therefore, we first **remove unproductive variables** then **remove unreachable variables**.
[Example](info-f-403.pdf#page=122).
### 4.4.4 Priority and associativity of operators
This part concerns the removal of #ambiguity. We need to modify the grammar in order to lift those. The idea is to make sure that the **only derivation trees** that will be returned by the parser are those that enforce the *priority and associativity* of the operators (for the example Id+Id * Id).

In order to have the priority, we need to ensure that the expression becomes a *sum of products of atoms*. An atom is basic building block (Id or Cst). The grammar becomes:![](Pasted%20image%2020231029113644.png)The derivation tree obtained (the only possible because we removed the #ambiguity).
