#chap1
Slides [[Slides190923.pdf]].
Syllabus [[info-f-403.pdf]] pages 2 to 30.
## 1.1 What is a language?
A **language** has a *semantic* and a *syntax*.

The **semantic** of a language is its *meaning* while the **syntax** of it is its *orthograph*.

```C
#include <stdio.h>
int i = 5; 
int f(int j) { 
	int i = j ;
	return i+1 ;
}

int main() { 
	printf("Hello world !");
	printf("%d %d", i, f(i+1));
	return 0;
}
	```
This program is syntactically correct.

"*Colorless green ideas sleep furiously*" is a sentence that is syntactically correct but its semantic is meaningless.

A program that compile $\to$ Syntax ok.
A program that does not what it is supposed to $\to$ Semantic not ok.
## 1.2 Formal languages
### Basic definitions
#definition
An **alphabet** is a *finite* set of symbols, they are denoted $\Sigma$.
- {0,1} is an alphabet
- $\mathbb{N}$ is not an alphabet because it is not finite.

A **word** on an alphabet $\Sigma$  is a *finite* sequence of symbols of $\Sigma$. They are denoted $u, v$ or $w$ in general. $\epsilon$ is used to represent the **empty word.**.
- If the alphabet is {0,1}, the words can be: 0011, 1011, 11010011, ...

$|w|$ is used to represent the length of the word $w$.

A **language** on an alphabet $\Sigma$ is a (possibly empty or infinite) set of words on $\Sigma$. An **empty language** is noted $\phi$.

--- 
For a #programming-language:
- The alphabet is the set of all the symbols
- A word is a program.
- A language is a set of all syntactically correct programs.
---
### The membership problem
The membership problem consists of knowing whether a word $w$ belongs to a language $L$.
#membership-problem
$\implies$ Given a language $L$ and a word $w$, say whether $w \in L$.
### Example of languages and related problems
1. The set $L_{Cid}$ of all non-empty words on $\Sigma_{C}$ (see example 1.7) that do not begin with a digit, is a language. It contains all valid C identifiers (variable names, function names, etc) and all C keywords (for, while, etc).
$$\Sigma_{C} = \{a, b, \dots, z, A, B, \dots , Z, 0, \dots, 9, \dots\}$$
2. The set $L_{odd}$ of all non-empty words on {0, 1} that end with a 1 is a language. It contains all the binary encodings of odd numbers.
3. The set $L_{()}$ of all words on $\Sigma$ = {(,)} which are well-parenthesised. Each closing parenthesis matches a previously open and still pending parenthesis, and each open parenthesis is eventually closed. Also called *Dyck Language*. #dycklanguage
	1. () belongs
	2. (()()) belongs
	3. ((() does not belong.
---
There are two ways to ensure whether a set of symbols is a word that belongs to Dyck language.

**Queue version**: for each (, add it to the queue. For each ), remove from the queue the first ( that has been added to the queue. It is a FIFO version.

**Stack version**: for each (, push. For each ), pop the last entered (. It is a LIFO version.

The queue version is not usable for a language with different types of brackets while the stack version adapts perfectly.

4. The set $L_{alg}$ of all algebraic expressions that use only the x variable, the + and ∗ operators and parenthesis, and which are well-parenthesised, is a language on the alphabet Σ = {(, ), x, +, ∗}. 
	1. For instance *((x+x)∗x)+x belongs* to this language.
	2. *)(x + x* does *not*, although it is a word on Σ.
5. The set $L_{C}$ of all syntactically correct C programs is a language.
6. The set $L_{Cterms}$ of syntactically C programs that terminate whatever the input given by the user is a language.
## 1.3 Compiler design
A #compiler got two phases.

The **analysis phase** that builds an abstract representation of the program structure. This phase consists in performing a lexical *analysis*/*scanning*, then a *parsing*.
Syntax errors are detected and reported during this phase. Finally, the analysis part usually contain a semantic analysis that performs type checking and reports typing errors.

After that, the **synthesis** **phase** translates the abstract representation of the program into the target language. Several optimisations can take place during this phase.
###  1.3.1 Scanning
#scanning #tokens
The scanner split the input string into a sequence of meaningful sub-strings that will be passed to the parser. It splits the input into **tokens**. 

A **token** is a pair $(\text{id}, \text{att})$ where id is the identifier of a lexical unit and att is an attribute (extra information about the token.)
![[Pasted image 20230921181327.png]]
The white space are ignored!

#identifier
During this phase, some preliminary analysis are also done. For example here, $j$ is identified as a *variable identifier* and the *same identifier* occurs in the lines just before. 

#lexical-unit #lexical #lexeme
The lexical analyser also recognize the predefined words like *int*, *return*, etc. Those words are in an abstract family of sub-strings called **lexical unit**. An element of this lexical unit is called a **lexeme**.

The scanner builds a symbol table, a list of all identifiers.

#scoping
But there is need to be careful for the **scoping**, when two variables are defined by the same identifier. When it happens, we leave the creation of the symbol table to the parser. 
#### Example
For the following code:
```C 
int i = 5;
int j = 3;
i = 9;
```
Initially the symbol table is empty, but when the lexeme in line 1 is matched, the scanner inserts it into the first entry (index 0) of the symbol table and returns the token *(identifier, 0)*.
- identifier denotes the symbolic name for identifiers
- The attribute is the index of the lexeme in the symbol table, it is therefore a unique symbolic name for the identifier i.

The symbol table would look like that at the #symbol-table:

| index | lexeme |
| ----- | ------ |
| 0     | i      |
| 1     | j      |
The line 3 won't change the symbol table. It will just get the variable that is in the index 0.
#### Scanner
#resume #scanner
The **scanner** is the first part of the compiling process. Its role is to *split* the input into a *sequence of lexemes* that are *associated to lexical units* and *returns a sequence of tokens* . It can be responsible for inserting identifiers into the symbol table, that contains all identifier matched so far, and possibly all keywords. The symbol table is thus used as a communication medium between the different compiling phases. But it remains a *local analysis* and can *not be used for scoping*.
### 1.3.2 Parsing
#parser #parsing
The scanner only does a local analysis of the code. While the **parser** has a more *global* view on the piece of code under analysis. It's objective is to *build an abstract representation of the code*.

#AST #tree
In order to do so, the parser builds an **abstract syntax tree (AST)** that also represents the structure of the input.

For the expression $i+y*5$ it would be:
![[Pasted image 20230925105304.png]]

But it can be done for much bigger code (like a while loop for example).
[Example of AST with while.](info-f-403.pdf#page=21)

To cope with the #scoping of identifier names, the compiler handles several symbol tables, one for each scope. Those symbols tables are arranged in a tree, in order to reflect the nesting scope.
[Example of symbol table tree.](info-f-403.pdf#page=22) #example
The general idea is that the compiler navigates through the tree during the execution and can then see the scope the identifier is in.
#### Parser
#resume #parser
The **parser** is the second part of the compiling process. It *receives a sequence of tokens* from the scanner. Its role is to *check whether this sequence of tokens respects a given syntax*, and, when it is the case, to *produce an abstract representation* (such as the abstract syntax tree) *of the program’s structure*, that will be used by the next phases of the compiling process. The parser can also populate the symbol table, in particular when *scoping* must be taken into account.
### 1.3.3 Semantic analysis
#semantic-analysis #semantic
The objective is to start analysing the semantic of the code, what the code means. It is divided in 3 big categories: scoping, typing and control flow.
#### Scoping
#scoping
During the semantic analysis phase, the compiler can analyse the links that exist between the declaration(s) of a name and the uses of this name throughout the code. This can also be performed during parsing thanks to the symbol table.
#### Type checking and type control
#type-checking #type
This part of the phase consists on checking that the type of each expression is respected when an operation is done. For example, an int can not be added to a float.

#decoration
In order to do so, the compiler can add the type to the #AST that has been build during parsing. This operation is called **decoration**.
![](Pasted%20image%2020230925111952.png)
#### Control flow
#control-flow #flow
The **control flow** refers to the *order in which the instructions of a program are executed*. Conditions, jumps, loops and function can alter the order. It is a part of the semantic analysis because a program can be syntactically correct but due to a wrong loop semantically incorrect.

To analyse this control flow, the semantic analyser can build an abstract representation thereof which is the **control flow graph**. A directed graph whose nodes represent the different statements of the program.

IF (B), THEN (T), ELSE (E).
![](Pasted%20image%2020230925113118.png)
It is often built from the #AST.
#### Semantic analyser
#resume #semantic-analysis 
The **semantic analysis** phase *receives the AST* built by the parser and *performs* a (limited) analysis of the semantics of the input code represented by this AST: *checking scoping of variables, checking for type consistency and detecting (potentially implicit) type conversions, checking for control flow inconsistency*. The **output** of the semantic analysis phase is a *decorated AST* (and, potentially, a control flow graph) that, together with the symbol table built during parsing, contains all the necessary information for the synthesis phase of the compiler.
### 1.3.4 Synthesis 
#synthesis
**Synthesis** is the phase during which the *outcome of the compiler is actually generated*. Generally an executable will be generated. It is composed by a lot of phases: *code optimisation, control flow optimisation, loop optimisation, constant propagation, promotion of parameters to references, intermediate language*. See them in the [syllabus](info-f-403.pdf#page=27).
## 1.4 Operations on words and languages
### 1.4.1 Operations on words

**Concatenation of two words** #concatenation #words
Given two words $w = w_{1}w_{2}\dots w_{n}$ and $v=v_{1}v_{2}\dots v_{l}$ , the concatenation of $w$ and $v$ is:
$$w . v = w_{1}w_{2}\dots w_{n}v_{1}v_{2}\dots v_{l}$$
By convention: $\epsilon . w = w.\epsilon=w$
$\to abc .de =abcde$ 
**Repeated concatenation**
$$w^{n}= w.w\dots w$$ n times.
$\to (ab)^{3}= ababab$
### 1.4.2 Operations on language
**Concatenation of languages** #concatenation #language
Let $L_{1}$ and $L_{2}$ be two languages.
$$L_{1} . L_{2} = \{w_{1}.w_{2}|w_{1} \in L_{1} \text{ and } w_{2} \in L_{2} \}$$
$\to \{ab, cd \} . \{e, f \} = \{abe, abf, cde, cdf\}$
$\to L . \{\epsilon \} = L =\{\epsilon \} .L$ 
$\to L . \phi = \phi$
**Repeated concatenation**
It is as the repeated concatenation of words:
$$L^{n}= L.L \dots L$$ n times.
**Kleene closure of L** #Kleene #closure
Contrairement a ma relation avec mon ex, Kleene a trouvé la closure qu'il fallait.
Denoted $L^*$, it is the language containing all words made up of an arbitrary number of concatenations of words from $L$:
$$L^*= \{w_{1}.w_{2}\dots w_{n}|n \geq 0 \text{ and for all } l\leq i\leq n :w_{i} \in L_{i} \}$$
$\to \{a\}^{*}= \{\epsilon, a, aa, aaa, aaaa, \dots\}$
$\to \{0,1\}^{*} = \text{ all binary words (including) } \epsilon$

A variation of the Kleene closure is $L^+$. It means that there is $n\geq 1$.

