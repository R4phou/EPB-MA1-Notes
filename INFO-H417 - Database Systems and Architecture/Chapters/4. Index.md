An #index allows to **access the block that holds records** by **organising the data** of the block and **quickly searching** for the records. It returns the *candidate records of the query*.
![](Pasted%20image%2020231203144704.png)
## 4.1 Conventional indexes
When accessing records, we can't access subpages. We **always take the whole pages** (~4kB). This is the *way that the data is normally organised in the storage*.
### 4.1.1 Dense Index
A #dense-index is in the mode "**a pointer per key**". 

To **search for a key**, we do a #sequential-scan of the index.

We can also use a dense index on a non-sequential file because we have a pointer that leads to the records.

Querying a #dense-index is **more efficient** than querying the sequential file because it:
- **allows us to have a different order than the storage**
- Thus we can sort the data in the index based on what we are looking for.
- And **searching through a sorted list** is **way faster**. Indeed we can use #binary-search.
![](Pasted%20image%2020231203150035.png)
Here, if we search for 25, go to Index 20 then search in the page.
### 4.1.2 Sparse Index
A #sparse-index is an #index where there is **a pointer per block**.  This allows thus to have less index entries.

It is not possible to use a sparse index on a non-sequential file because for the sparse index to work, we need to be sure that the pages are sorted. If we are looking for 20, it  must be between 10 and 50. $\to$ sorted sequential file on the same key as the index.

To **search for the key 25**. It is not in the index records, so we have to look for it in the previous page. We don't know if it is there or not but we have to go through the records of the page sequentially.
![](Pasted%20image%2020231203151111.png)
The advantage of the **sparse index** is that we can **add a second level** if the first level index has so many pages. This *allows to speed up the search*.![](Pasted%20image%2020231203151430.png)
### 4.1.3 Dense VS Sparse
The #sparse-index has **less index space per record** and can **keep more of index in memory**. This reduces the number of access (mean cost in the database).

The #dense-index can **tell if any record exists without accessing the file** but is bigger, we are not always able to store the whole index in memory.
### 4.1.4 Duplicate keys
#skip [3.-Indexing](3.-Indexing.pdf#slide8).
If we have duplicate keys (several times the same key), how does the dense and sparse index acts?

The #dense-index would normally have one pointer per key. But a solution here is to have a pointer per value of key! **But this requires that the files needs to be sorted in the same order as the index!**
### 4.1.5 Secondary indexes
In #secondary-index, the **data is not stored sorted by the key**.![](Pasted%20image%2020231203160312.png)Here a #sparse-index won't work because it is not sorted! But a #dense-index **will work** as there is one pointer per key.
![](Pasted%20image%2020231203160444.png)
Now, a #sparse-index **can be added on the high level** to navigate through the keys of the pointers of the #dense-index.

$\implies$ **With secondary indexes**: lowest level is dense and other levels are sparse.![](Pasted%20image%2020231203160701.png)
### 4.1.6 Duplicate values & secondary indexes
If we have a #secondary-index and #duplicate-values. We cannot keep one pointer per key because it leads to **an excess of overhead (disk space and search time)**. And it is not possible to only keep one overhead because there would be variable size records in the index  (not supported in order to do #binary-search).
![](Pasted%20image%2020231203162455.png)

The solution is to use #buckets, it allows to divide in pages that are ordered and points to the keys.
##### Example
Imagine having the indexes *names* (primary), *dept* (secondary) and *floor* (secondary). And the records EMP.

For the query: Get employees in (Toy Dept) and (2nd floor)![](Pasted%20image%2020231203163031.png)because we have the buckets, we can intersect the pointers and **we don't need to access the records**.
### Conclusion
The #conventional #index are **simple** and the **index is a sequential file so it is easy for scans**. But the **inserts are expensive** or we *loose sequentiality and balance*.![](Pasted%20image%2020231203164438.png)
## 4.2 B-trees
The #B-Tree #index **gives up on sequentiality** and **tries to get balance**, an unbalanced tree is far from the log(n) insertion and search. Here is an example of b-tree of 3 levels (n=3).![](Pasted%20image%2020231203164603.png)
### 4.2.1 Nodes
#### Non-leaf node
A #node is a #non-leaf **if it points to another node**.![](Pasted%20image%2020231203164834.png)
#### Sample leaf node
A #node is a #leaf **if it points directly to a record** (that has the key stocked in the node).![](Pasted%20image%2020231203164931.png)
#### Size of nodes
The **size** of the nodes is **fixed**, it has **n+1 pointers** and **n keys**.

And we don't want them to be too empty, there should be at least:
- $\lceil (n+1)/2\rceil$ pointers for #non-leaf 
- $\lfloor (n+1)/2\rfloor$ pointers to data for #leaf  
![](Pasted%20image%2020231204153825.png)Here is an example for **n = 3**.
### 4.2.2 Rules of a B-tree
There are **three rules for a B-tree of order n**:
1. All leaves at same lowest level (the tree needs to be balanced)
2. Pointers in leaves point to records except for "sequence pointer"
3. Number of pointers/keys for B-Tree![](Pasted%20image%2020231204154131.png)
### 4.2.3 Insert into a B-tree
All examples here are with **n = 3**.
![](Pasted%20image%2020231204154616.png)
In this example, we have a space available in the leaf at the beginning.
#simple-case When inserting **32**, it is trivial. 

#leaf-overflow When inserting **7**, we need to move 3 and 5 in a new #leaf and update the parent #non-leaf node with another pointer.

![](Pasted%20image%2020231204154923.png)
#non-leaf-overflow When inserting **160**, we need to move 180 to another #non-leaf node and create a new #leaf. We thus also have to update the root node.

#new-root When inserting **45**, we need to create a new #leaf node for 40 and 45 (40 to balance the tree), then because the #non-leaf parent node is already full, create another #non-leaf node. And thus, a **new root** node also needs to be created.

These are the **4 ways** of inserting a key in the B-tree. Note that it can cost some time.
### 4.2.4 Deletion of a key from B-tree
All examples here are for **n = 4**. The #simple-case is trivial.![](Pasted%20image%2020231204155950.png)On the **left** of the image #coalesce-with-neighbour and on the **right** #redistribute-keys 
#coalesce-with-neighbor (sibling), we can remove the #leaf and move 40 to the #leaf on the left. The #non-leaf can be updated to remove the 40 pointer.

#redistribute-keys To keep the B-tree balanced, the pointer 35 needs to change leafs and the #non-leaf parent needs to be updated to the new starting value of the right leaf.

![](Pasted%20image%2020231204160400.png)
This is an example of #non-leaf-coalesce, when deleting **37**. To keep the balance, we can remove the #leaf and move the 30 to the leaf on its left. We can also remove the pointer of the #non-leaf parent.

To keep the balance of the #non-leaf level, the 40 pointer can be moved to the left #non-leaf. And thus the right non-leaf can be deleted. 

We only have to update the left #non-leaf with the root value because otherwise it would be a list. This results that the #non-leaf becomes the #new-root!

**Note**: Often, coalescing is **not implemented** because it is too hard and not worth it!
## 4.3 Hashing schemes
#sitapaslaflemmetupeuxleliremaisleprofaditosef

