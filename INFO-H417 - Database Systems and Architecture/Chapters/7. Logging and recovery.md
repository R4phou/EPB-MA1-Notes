[Lecture 7 - Logging and recovery](Lecture%207%20-%20Logging%20and%20recovery.pdf#page=2)
## 7.1 Consistency and Integrity constraints
The predicates data must satisfy #integrity or #consistency #constraints.

Some examples of constraints:
- x is key of relation R
- $x\to y$ holds in R
- Domain(x) = {Red, Green, Blue}
- $\alpha$ is valid index for attribute x of R
- no employee should make more than twice the average salary
- ...
### 7.1.1 Consistency constraint
A #state is #consistent **if it satisfies all constraints**.

A #DB is #consistent **if the DB is in a consistent state**.

We can observe that a database **cannot always** be consistent.
	$a_{1}+a_{2}+\dots+a_{n}=TOT$
	Deposit 100 $\$$ in $a_{2} \to a_{2}\leftarrow a_{2}+100$ and  $TOT \leftarrow TOT + 100$ 
	![](Pasted%20image%2020231228144305.png)There is a transition state that can not be consistent
### 7.1.2 Transaction
![](Pasted%20image%2020231228144438.png)A #Transaction is a **collection of actions** that **preserves** #consistency. This is done as a *vector of transition between two consistent states of the DB*.

A **big assumption**:
If T starts with consistent state + T executes in isolation $\implies$ T leaves consistent state.

A transaction will not "make" the database in a consistent state if it was not before.

#correctness:
- if we stop running transactions, the DB left is #consistent 
- Each transaction sees a consistent DB.

**If the database fails during a transaction**, the **DB looses its consistency**. Otherwise it keeps it!
## 7.2 Consistency violation
The #consistency of the database can be violated by different factors such as:
- **System crash** (memory loss, CPU halts, resets,... ).
- Media failure or catastrophe (not seen in this course).
### 7.2.1  Preventing consistency violation
The **intuitive solution** is to store a "backup" of the whole database and do that very often. That is *correct and maintains the consistency*, but it would **take too much space and time**!

Another solution is to maintain a replica, but it is also needy in terms of space and time (good solution for media storage).

The most efficient solution is to create a backup of what is changed during the transaction before the transaction. This allows to gain some storage.

### 7.2.2 Protocol
The idea is to **do transactions in the memory**, and fetch the corresponding pages from the disk before processing.
![](Pasted%20image%2020231228145710.png)
The disk is the **safe space**, once on the disk, the data is **protected**.

The #protocol to do that without destroying the db is the following:
- Input(x): block containing x $\to$ memory
- Output(x): block containing x $\to$ disk         *if something has been outputted, the data it contained is consistent $\to$ save action*
- Read(x, t)
	- do input(x) if necessary,
	- else t $\leftarrow$ value of x in block
- Write(x,t):
	- do input(x) if necessary,
	- value of x in block $\leftarrow$ t                         *updating the value of x*
## 7.3 Key problem
Sometimes there are **problems**, as here with the #key-problem.

Here we have an example of **unfinished transaction**:
We have the **constraint** $A = B$ and $$T_{1}: A \leftarrow A \times 2;B\leftarrow B \times 2$$If everything goes according to plan but there is a failure between the Output(A) and Output(B), we would **have modified the disk with and error** because B won't be modified in the disk.![](Pasted%20image%2020231103104732.png)
This is a problem that could be solved by introducing #atomicity: **executing all actions of a transaction or none at all!**
## 7.4 Undo logging
We can now introduce **immediate modification** with the #Undo-logging. The idea is to **log important events** to keep track of the changes in case of system failure.![](Pasted%20image%2020231103104948.png)Here for example, we log the old value **before changing in the disk**. When a #commit is made, the database is in a #consistent state. It is a *proof that all needed to be done is done*.

A complication that could occur is that the **log is first written in memory** and **not written** to the disk on every action.

On the example of the **BAD STATE #1**, we arrive there because we need to write in the Log before changing in the disks:

A second example is the **BAD STATE #2**, we see that we *need to develop a protocol to synchronise log and actions*. The idea is to ask the buffer manager to "flush" in a certain order. This is done by #Undo-logging 
![](Pasted%20image%2020231228151002.png)As we can see, the value is updated but in the log it is not yet written, there is a problem of synchronisation.
### 7.4.1 Undo logging protocol
(1) **For** **every action generate undo log record** (containing old value).
(2) Before x is modified on disk, **log records pertaining to x must be on disk** (write ahead logging: WAL).
(3) **Before commit** is flushed to log, **all writes of transaction must be reflected on disk**.

It is **better to have logged** **but not done** than the inverse. This is why we *write first the log* on disk before changing the values on the disk.
### 7.4.2 Undo logging example
Here is an example of the last example:![](Pasted%20image%2020231228151254.png)
### 7.4.3 Recovery rules
![](Pasted%20image%2020231228151427.png)This is the correct version of the rules. Another version here [Lecture 7 - Logging and recovery](Lecture%207%20-%20Logging%20and%20recovery.pdf#page=28). Is not correct as the order of the x is not correct. We **need to go latest to earliest (bottom up)** and not top-down.
![](Pasted%20image%2020231228151601.png)
If failure happens during recovery, then **no problem** as *undo* is  *idempotent*.
## 7.5 Redo logging
This is the opposite as #Undo-logging.

In #redo-logging, we want to **put log in disk before the modification**.![](Pasted%20image%2020231228152020.png) 
1. Value is changed in memory
2. Logs are written
3. Output changed in DB
4. Add finish of the logging.
### 7.5.1 Redo logging rules
(1) For **every action**, generate *redo log record* (containing new value)
(2) **Before X is modified on disk** (DB), *all log records for transaction that modified X* (including commit) *must be on disk* 
(3) **Flush log at commit** 
(4) **Write END record** after DB updates flushed to disk
### 7.5.2 Redo logging example
![](Pasted%20image%2020231228152326.png)
Here the main differences with undo logging are that:
- New values are logged after they are changed in the memory
- The logs are flushed and then the values is written in the disk.
### 7.5.3 Recovery rules
![](Pasted%20image%2020231228153142.png)This time, the order is from earliest to latest (top down).
## 7.6 Optimising flushes
We want to **delay DB flushes** for hot objects as these are writes and we don't want to do to many of them. We do that by combining <Ti, end> records.

For example, if multiple query need to update a certain item. The solution is to bring #checkpoint.
### 7.6.1 Checkpoints
A #checkpoint consists in **marking the log** such that *all that came before does not need to be processed in case of crash recovery*.
- **Good** for not having an ever increasing log that we need to scan entirely at each crash.
- **Only needs** to process what comes after for both #Undo-logging and #redo-logging.

This is done by **periodically**:
1. Do not accept new transactions $\to$ *freeze the DB  periodically, blocking new transactions*
2. Wait until all transactions finish
3. Flush all log records to disk (log) 
4. Flush all buffers to disk (DB) (do not discard buffers) 
5. Write “checkpoint” record on disk (log) 
6. Resume transaction processing
### 7.6.2 Example
![](Pasted%20image%2020231228154424.png)
## 7.7 Key drawbacks
#Undo-logging - increased #IO costs even as we put data to the disk early and free the memory. But we flush more often which leads to IO costs.

#Redo-logging - need to keep all modified blocks in memory until commit. Stack things in memory for a longer period requires **less IOs**.

The solution is #undo-redo-logging.
We update <Ti, Xid, New X val, Old X val>
	$X id$ is the reference to the page X.
### Rules
- Page X can be flushed before or after Ti commit
- Log record flushed before corresponding updated page (*Write Ahead Logging* #WAL)
- Flush at commit (log only)
	- And flush log when we commit.
### Undo/Redo Example
![](Pasted%20image%2020231228155413.png)
Note that at the end, there is **no need to flush the commit**. There is no need to log manually, we can *let the buffer manager decide when*.

**If a commit** (it is a committed #transaction) #redo-logging **ensures that committed changes**, which *may be in the buffer but not yet written to stable storage*, **can be recovered by reapplying the changes from the redo log**.

**Without a commit**, it implies that the *changes made by the transaction are not considered permanent*. #Undo-logging is crucial in this scenario because, in the event of a system failure, it *allows the DBMS to roll back the incomplete transaction and maintain the consistency of the database*.

Note that simple checkpoints are not affordable anymore. The logging size becomes critical and we have to scan the wh