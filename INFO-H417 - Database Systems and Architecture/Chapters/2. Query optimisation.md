[INFO_H417 2. Query optimisation](INFO_H417%202.%20Query%20optimisation.pdf#page=56).
## 2.1 System R
For this part, a paper needed to be read over the **System R: Relational approach to Database Management**.
Let's answer to the 8 questions:
### 1. Architecture components of System R
We have SQL that is translated into RA to go to the Relational Data System.

The **relational data system** is where the relational algebra takes place. The *data is organised at a logical level* compared to the previous step where it was stored physically. It also *handles concurrency*.

We then move to the **relational storage system** by reading and writing in it. This part is the part that *recovers from crashes*.
### Language used by System R for querying
SEQUEL. (later to be SQL).
### What is a catalogue
A #catalogue is itself a **database**, it is a set of relations which are **storing metadata about other databases that the system is managing**.

The #metadata about those databases is basically the tables, attributes, types, size and statistics such as holes and distribution of these databases.

The catalogue allows to *verify if an attribute is in a table*,... It also *verifies that the operations matches the required datatypes*.

The correctness and statistics assists in the decision that we have to make!
### What is a cursor
A cursor is the "object" that reads the data, it is a sort of pointer that navigates through the data. This method is still used.
### What is a clustering image
A **clustering image** is a sort of #index. It is the order in which the data is physically stored. There *can't be more than one* because *data is physically ordered*.

#todo access path and parameters of cost estimation
## 2.2 Query optimisation
As we know there are multiple ways of evaluating a given query:
- equivalent expressions
- different algorithms for each operations (join can be done from a lot of different ways depending on the size of the two relations).

In order to determine the fastest and the optimal solution, we build a **query plan**: it *defines exactly which algorithm to use for each operation and how the execution of the operation if coordinated*.![](Pasted%20image%2020231104112301.png)
### 2.2.1 Cost-based query optimisation
Cost difference between evaluation plans for a query can be enormous 
- E.g., seconds vs. days in some cases

**Steps** in #cost-based query optimisation
- *Generate logically equivalent expressions using equivalence rules* 
- *Annotate resultant expressions to get alternative query plans* 
- *Choose the cheapest plan based on estimated cost* 

**Estimation of plan cost based on**: 
- *Statistical information about relations*
	- Examples: number of tuples, number of distinct values for an attribute
- *Statistics estimation for intermediate results* 
	- to compute cost of complex expressions
- *Cost formulae for algorithms*, computed using statistics.

For example, the order of execution of multiple joins can change a lot the cost. Therefore, an algorithm is used to determine the best order and **store this choice** thanks to a #dynamic-programming. (Memoisation).
### 2.2.2 Viewing query evaluation plans
In order to know what is done during a query, write:
```SQL
EXPLAIN ANALYSE <query>
```
### 2.2.3 Generating equivalent expressions
Two *relational algebra expressions* are said to be #equivalent if the *two expressions generate the same set of tuples on every legal database instance* (the order of tuples is irrelevant).

In **SQL**, **inputs** and **outputs** are *multisets (bag) of tuples*: Two expressions in the multiset version of the relational algebra are said to be #equivalent if the two expressions generate the same multiset of tuples on every legal database instance.

An #equivalence-rule says that **expressions of two forms are equivalent**, so *one can replace the other*.
#### Equivalence rules
![2.-Database-System-Architecture](2.-Database-System-Architecture.pdf#page=12)
##### Examples
There are multiple examples: [2.-Database-System-Architecture](2.-Database-System-Architecture.pdf#page=18).
### 2.2.4 Enumeration of equivalent expressions
The **query optimiser uses** #equivalence-rule to systematically generate expressions equivalent to the given expression.

**Method**:
- Repeat 
	- apply all applicable equivalence rules on every sub expression of every equivalent expression found so far 
	- add newly generated expressions to the set of equivalent expressions 
- Until no new equivalent expressions are generated above
### 2.2.5 Cost estimation
The cost of each operator (detailed in future chapters) are calculated by **using statistics** of inputs relations. Note that the inputs can be the results of sub-expressions.
### 2.2.6 Join order Optimisation algorithm
By using #dynamic-programming, to find the **best join tree** for a set of n relations:
![](Pasted%20image%2020231104120156.png)
![](Pasted%20image%2020231104120214.png)
Here we have an example of the use of #memoisation.
### 2.2.7 Cost of cost based optimisation
With dynamic programming, the time complexity of join order optimization is O(3n). 
With n = 10, this number is 59000 instead of 176 billion!
Space complexity is O(2n) 
$\to$  **Therefore, System R restricts only to left-deep join trees - good for pipelined execution**

A #left-deep-join-tree is tree such as here below. It *enables pipelining and diminish the computation errors of the estimate*. It **restricts** that **every join** has **at least one relation that is already in the database**! Therefore, it allows to reduce the cost of cost-based optimisation.

If the tree is not a left-deep join tree, then we would have intermediate relations that takes storage and time!![](https://lh7-us.googleusercontent.com/38WzPIWIDB7GCTnBTM8kvVDSptRxcjVHFEMtTYmXblemexijLaKBMnAt55Tf513VeLvrgP685uMGploGvNs6wk6RRJk-aSprxVSkPbsnE_dD4TtUmBcN_gP1wgwN6bP3MNnutSbI5dZIqGDbMGcVd6h4Tw=s2048)For a set of n relations: Consider n alternatives with one relation as right-hand side input and the other relations as left-hand side input.

Time complexity of **finding best join order is $O(n 2^n)$ - compared to $O(3^n)$**!

We can conclude that even with an optimised version of cost-based optimisation, it **is expensive**, but worthwhile for queries on large datasets!

#Note: **optimisers** have **budget time**, when the timeout happens, they use the best solution found so far.
## 2.3 Heuristic optimisation
![](Pasted%20image%2020231104121152.png)

![](Pasted%20image%2020231104121434.png)
